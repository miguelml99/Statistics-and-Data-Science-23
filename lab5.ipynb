{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0681d90",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'otter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize Otter\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01motter\u001b[39;00m\n\u001b[0;32m      3\u001b[0m grader \u001b[38;5;241m=\u001b[39m otter\u001b[38;5;241m.\u001b[39mNotebook(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlab5.ipynb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'otter'"
     ]
    }
   ],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab5.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "594432e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T01:00:59.622686Z",
     "iopub.status.busy": "2023-03-21T01:00:59.622387Z",
     "iopub.status.idle": "2023-03-21T01:01:00.136694Z",
     "shell.execute_reply": "2023-03-21T01:01:00.136100Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "rng_seed = 454"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1581af29",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h1><center>SDSE Lab 5 <br><br> Scikit-learn, logistic regression, feature selection, and regularization</center></h1>\n",
    "\n",
    "---\n",
    "\n",
    "In this lab we will build a model for diagnosing breast cancer from various measurements of the tumor. This lab also introduces [scikit-learn](https://scikit-learn.org/stable/), which is a package for performing a host of machine learning tasks. This model building activity will demonstrate the use of scikit-learn's train-test data splitter, standard scaler, pipelines, cross-validation, and LASSO regularization. \n",
    "\n",
    "\n",
    "There are 15 parts split into four sections.\n",
    "\n",
    "**Prelminaries**\n",
    "\n",
    "1. Load the data\n",
    "2. Extract test data\n",
    "3. Normalize the data\n",
    "\n",
    "**Simple logistic regression**\n",
    "\n",
    "4. Most correlated feature\n",
    "5. Train simple logistic regression\n",
    "6. Cross-validation\n",
    "7. Create a scikit-learn pipeline\n",
    "8. Test simple linear regression\n",
    "\n",
    "**Set selection**\n",
    "\n",
    "9. Forward stepwise selection\n",
    "10. Backward stepwise selection\n",
    "11. Selected model\n",
    "\n",
    "**Regularization**\n",
    "\n",
    "12. LASSO regularized logistic regression\n",
    "13. Selected model\n",
    "14. Best features\n",
    "15. Final model performance\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95e91e4",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<h1><center><font color='purple'> Preliminaries</font><br></center></h1>\n",
    "\n",
    "\n",
    "# 1. Load the data\n",
    "\n",
    "This is a [classic dataset](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)) that originates at the University of Wisconsin and is included in the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php), as well as in scikit-learn's collection of [toy datasets](https://scikit-learn.org/stable/datasets/toy_dataset.html). It can be loaded with the [load_breast_cancer](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html) method. Passing `as_frame=True` prompts this method to return a pandas DataFrame. \n",
    "\n",
    "This dataset encodes a benign tumor as a 1 and a malignant tumor as a 0. We'll flip this so that the encoding aligns with our common notion of \"positive\" and \"negative\" diagnoses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301814f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T01:01:00.139259Z",
     "iopub.status.busy": "2023-03-21T01:01:00.138930Z",
     "iopub.status.idle": "2023-03-21T01:01:00.436424Z",
     "shell.execute_reply": "2023-03-21T01:01:00.435854Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer(as_frame=True).frame\n",
    "data['target'] = 1-data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5ce83a",
   "metadata": {},
   "source": [
    "Use `data.info()` to display a summary of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e2ebf72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T01:01:00.438955Z",
     "iopub.status.busy": "2023-03-21T01:01:00.438742Z",
     "iopub.status.idle": "2023-03-21T01:01:00.448631Z",
     "shell.execute_reply": "2023-03-21T01:01:00.447915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  target                   569 non-null    int32  \n",
      "dtypes: float64(30), int32(1)\n",
      "memory usage: 135.7 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772eb0dc",
   "metadata": {},
   "source": [
    "# 2. Extract test data\n",
    "\n",
    "The first step is to set aside a portion of the data for final testing. Use scikit-learn's [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to create a 20/80 split between testing and training datasets. \n",
    "\n",
    "Note: `train_test_split` takes these arguments:\n",
    "1. The model input samples: Use `data.iloc` to select all rows and all but the last column. \n",
    "2. The model output samples: The last column of `data` (named \"target\")\n",
    "3. `test_size` is the portion of the data reserved for testing. \n",
    "4. Always pass `random_state=rng_seed` to fix the random seed and ensure reproducibility of the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c8d6ee0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T01:01:00.450909Z",
     "iopub.status.busy": "2023-03-21T01:01:00.450723Z",
     "iopub.status.idle": "2023-03-21T01:01:00.528392Z",
     "shell.execute_reply": "2023-03-21T01:01:00.527816Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(data.iloc[:,:-1],\n",
    "                                                data['target'], \n",
    "                                                test_size=0.2, \n",
    "                                                random_state=rng_seed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adfc3048",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgrader\u001b[49m\u001b[38;5;241m.\u001b[39mcheck(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grader' is not defined"
     ]
    }
   ],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557ea104",
   "metadata": {},
   "source": [
    "# 3. Normalize the data\n",
    "\n",
    "Normalizing the data (i.e. subtracting the mean and dividing by the standard deviation) can be useful for improving the numerical behavior of the training process. From a theoretical standpoint, normalizing the data should have no impact on un-regularized logistic regression; logistic regression is a \"scale invariant\" model. However it can be helpful for several reasons:\n",
    "a) It improves numerical stability by equalizing the scales of the features. \n",
    "b) It enables comparisons between feature coefficients (a larger coefficient implies greater influence of the feature).\n",
    "c) We typically want some degree of regularization, and regularized logistic regression is not scale invariant. \n",
    "\n",
    "Here we will use a [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) preprocessing object to create normalized versions of the training and test data. The training data is done for you. Repeat the process to obtain a normalized version of the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d70e2285",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T01:01:00.543464Z",
     "iopub.status.busy": "2023-03-21T01:01:00.543299Z",
     "iopub.status.idle": "2023-03-21T01:01:00.553214Z",
     "shell.execute_reply": "2023-03-21T01:01:00.552712Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "Xtrain_norm = StandardScaler().fit_transform(Xtrain)\n",
    "Xtrain_norm = pd.DataFrame(Xtrain_norm, index=Xtrain.index, columns=Xtrain.columns)\n",
    "\n",
    "Xtest_norm = StandardScaler().fit_transform(Xtest)\n",
    "Xtest_norm = pd.DataFrame(Xtest_norm, index=Xtest.index, columns=Xtest.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dd9111",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07993b2d",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<h1><center><font color='purple'> Simple logistic regression</font><br></center></h1>\n",
    "\n",
    "\n",
    "# 4. Most correlated feature\n",
    "\n",
    "Our first model will be a simple logistic regression model based on the single feature that best correlates with the output. Find this feature and save its name (header value) to `best_single_feature`. \n",
    "\n",
    "Note: The tests for this part are hidden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "046218d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T01:01:00.580223Z",
     "iopub.status.busy": "2023-03-21T01:01:00.580009Z",
     "iopub.status.idle": "2023-03-21T01:01:00.586302Z",
     "shell.execute_reply": "2023-03-21T01:01:00.585761Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "C = data.corr()\n",
    "\n",
    "# vector correlations between the features and target\n",
    "corr_target = C['target']\n",
    "# sorted corr_target_sort\n",
    "corr_target_abs = corr_target.abs()\n",
    "corr_target_sort = corr_target_abs.sort_values(ascending=False)\n",
    "corr_target_sort = corr_target_sort.tail(-1)\n",
    "\n",
    "# top correlation feature with target\n",
    "best_single_feature = corr_target_sort.index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e1b13a",
   "metadata": {},
   "source": [
    "# 5. Train simple logistic regression\n",
    "\n",
    "Next we train the simple logistic regression model for the feature that was selected in the previous part. We will use scikit-learn's implementation of [logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) for this purpose. \n",
    "\n",
    "1. Pass `random_state=rng_seed` into the LogisticRegression constructor to ensure repeatability of the results. \n",
    "2. Call the [`fit`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.fit) function of the model object, passing in the training data. In this case the model inputs correspond to the single best feature already identified.\n",
    "3. Extract the trained model coefficients. The intercept term $\\theta_0$ is contained in the `intercept_[0]` attribute of the model. The remaining coefficients $\\theta_1$ through $\\theta_P$ (in this case just $\\theta_1$) are in `coef_[0,:]`.\n",
    "\n",
    "This has been done for you with the original (un-normalized) input data. Repeat the exercise with the normalized data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10207d76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T01:01:00.594286Z",
     "iopub.status.busy": "2023-03-21T01:01:00.594125Z",
     "iopub.status.idle": "2023-03-21T01:01:00.620277Z",
     "shell.execute_reply": "2023-03-21T01:01:00.619713Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.4650745287470324 [7.80674558]\n",
      "-1.085050522907755 [3.44438434]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_nonorm = LogisticRegression(random_state=rng_seed)\n",
    "model_nonorm.fit(Xtrain[[best_single_feature]],ytrain) \n",
    "print(model_nonorm.intercept_[0], model_nonorm.coef_[0,:])\n",
    "\n",
    "model_norm = LogisticRegression(random_state=rng_seed)\n",
    "model_norm.fit(Xtrain_norm[[best_single_feature]],ytrain) \n",
    "print(model_norm.intercept_[0], model_norm.coef_[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf53ef2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac405d2",
   "metadata": {},
   "source": [
    "# 6. Accuracy by cross-validation\n",
    "\n",
    "Accuracy is an important performance metric for classification models. It is computed as the ratio of correct predictions to total predictions. Hence it approximates the probability that the prediction is correct. \n",
    "\n",
    "K-fold cross-validation is an evaluation technique that provides a more robust estimate of model performance (e.g. accuracy) than simple evaluation. It does this by splitting the training set into K equal parts (or \"folds\"), and then training K separate models, each with one of the K parts as validation data and the others as training data. \n",
    "\n",
    "Cross-validation is implemented in scikit-learn's [`cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) function. We will use 3-fold cross-validation to evaluate the accuracy of both the un-normalized and normalized models.\n",
    "\n",
    "Note the following:\n",
    "1. The first three arguments for the `cross_val_score` are the model, the training input data, and the training output data. These last two entries are the same as were passed to the `fit` function in the previous part. \n",
    "2. Use `scoring='accuracy'` to set the evaluation metric to accuracy. Use `cv=3` to set the number of folds to 3. \n",
    "3. The function should return 3 values of accuracy -- one for each of the folds. Store the *mean* of these as `acc_nonorm` and `acc_norm` for the un-normalized and normalized models respectively. \n",
    "4. Note the improvement due to normalization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350c5c85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T01:01:00.634030Z",
     "iopub.status.busy": "2023-03-21T01:01:00.633862Z",
     "iopub.status.idle": "2023-03-21T01:01:00.669551Z",
     "shell.execute_reply": "2023-03-21T01:01:00.669025Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "acc_nonorm = ...\n",
    "acc_norm = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0405fc45",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e029131e",
   "metadata": {},
   "source": [
    "# 7. Create a pipeline\n",
    "\n",
    "Testing the model using `Xtest_norm` presents a problem. This test dataset was created by normalizing `Xtest`, however we will usually apply the model to individual samples (tumor measurements), and hence we will not have a standard deviation to divide by. Instead, we will have to normalize using the mean and standard deviations of the *training* data. Hence, these values become parameters of a larger model that includes the StandardScaler and any other preprocessing steps. \n",
    "\n",
    "Scikit-learn provides a *pipeline* class to collects all of the preprocessing, feature transformation, and modeling components into a single object with `fit` and `predict` methods. You can  read the documentation on [pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) to learn more. \n",
    "\n",
    "Each component in the pipeline is identified with a string name. The following code creates a pipeline with a `StandardScaler` tagged as `scaler`, followed by a logistic regression model tagged as `logreg`.\n",
    "\n",
    "``` python\n",
    "pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                 ('logreg', LogisticRegression(random_state=rng_seed)) ])\n",
    "```\n",
    "\n",
    "Train the pipeline using its `fit` method, and evaluate its accuracy with 3-fold cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c406766",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T01:01:00.682869Z",
     "iopub.status.busy": "2023-03-21T01:01:00.682614Z",
     "iopub.status.idle": "2023-03-21T01:01:00.712156Z",
     "shell.execute_reply": "2023-03-21T01:01:00.711594Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline(...)\n",
    "pipe.fit(...) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99143022",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16852bdb",
   "metadata": {},
   "source": [
    "# 8. Test simple linear regression\n",
    "\n",
    "Here we will do something that is usually not allowed: we will use the test data on three different models. This is ok in this context because we are not making any modeling decisions based on the outcome. We are simply learning about the differences between the three approaches to simple logistic regression that we have seen thus far: no normalization, normalization without a pipeline, and normalization with a pipeline. \n",
    "\n",
    "We will use the [`accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) method to compute the accuracy in each case. We are not using cross-validation in this case because we do not wish to re-train the models, only to evaluate their performance. \n",
    "\n",
    "Notice that `accuracy_score` takes in the true output and the predicted output. Use the `predict` function of the model to obtain the predicted output (we call it `yhat`).  Here are the three cases. In each case you should think about which input to provide to the prediction function: `Xtest[...]` or `Xtest_norm[...]`\n",
    "\n",
    "+ `acc_nonorm_test`: Test accuracy of `model_nonorm`\n",
    "+ `acc_norm_test`: Test accuracy of `model_norm`\n",
    "+ `acc_pipe_test`: Test accuracy of `pipe`\n",
    "\n",
    "How would you expect these three values to be ordered? Does your result agree with that expectation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f266e85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T01:01:00.732257Z",
     "iopub.status.busy": "2023-03-21T01:01:00.732099Z",
     "iopub.status.idle": "2023-03-21T01:01:00.743251Z",
     "shell.execute_reply": "2023-03-21T01:01:00.742703Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "yhat = model_nonorm.predict(...)\n",
    "acc_nonorm_test = accuracy_score(ytest, yhat)\n",
    "\n",
    "yhat = ...\n",
    "acc_norm_test = ...\n",
    "\n",
    "yhat = ...\n",
    "acc_pipe_test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a499694",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0997c7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "<h1><center><font color='purple'>Set selection</font><br></center></h1>\n",
    "\n",
    "\n",
    "\n",
    "# 9. Forward stepwise selection\n",
    "\n",
    "Following is code that executes forward stepwise feature selection according to the pseudo-code provided in the lecture. Read and understand this code. \n",
    "\n",
    "+ Make sure that you can map every part to the corresponding part of the pseudo-code.\n",
    "+ Notice the use of sets and set arithmetic. \n",
    "+ The outcomes are stored in dictionary named `fwd`.\n",
    "\n",
    "This part has no deliverables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828f1102",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T01:01:00.762699Z",
     "iopub.status.busy": "2023-03-21T01:01:00.762537Z",
     "iopub.status.idle": "2023-03-21T01:01:00.765259Z",
     "shell.execute_reply": "2023-03-21T01:01:00.764783Z"
    }
   },
   "outputs": [],
   "source": [
    "features = Xtrain.columns\n",
    "P = len(features)\n",
    "curlyP = set(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd7465c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T01:01:00.767246Z",
     "iopub.status.busy": "2023-03-21T01:01:00.766840Z",
     "iopub.status.idle": "2023-03-21T01:01:18.455322Z",
     "shell.execute_reply": "2023-03-21T01:01:18.454422Z"
    }
   },
   "outputs": [],
   "source": [
    "curlyS = [set() for i in range(P+1)]\n",
    "acc = np.full(P+1,-np.inf)\n",
    "\n",
    "for p in range(1,P+1):\n",
    "    print(p)\n",
    "    \n",
    "    curlyA = [set() for i in range(P-p+1)]\n",
    "    acckappa = np.empty(P-p+1)\n",
    "    \n",
    "    remain = np.sort(list(curlyP-curlyS[p-1]))\n",
    "    for kappa, phip in enumerate(remain):\n",
    "        \n",
    "        # Akappa\n",
    "        curlyA[kappa] = curlyS[p-1].union({phip})\n",
    "        \n",
    "        # train the logistic regression model\n",
    "        xtrain = Xtrain[list(curlyA[kappa])]    \n",
    "        model = Pipeline([('scaler', StandardScaler()), \n",
    "                          ('logreg', LogisticRegression(random_state=rng_seed)) ])\n",
    "        model.fit(xtrain,ytrain) \n",
    "        \n",
    "        # evaluate the model\n",
    "        acckappa[kappa] = cross_val_score(model, xtrain, ytrain, cv=3, scoring='accuracy').mean()\n",
    "\n",
    "    kappastar = np.argmax(acckappa)\n",
    "        \n",
    "    curlyS[p] = curlyA[kappastar]\n",
    "    acc[p] = acckappa[kappastar]\n",
    "\n",
    "# best p\n",
    "pstar = np.argmax(acc)\n",
    "\n",
    "# store the result\n",
    "fwd = {\n",
    "    'pstar' : pstar,\n",
    "    'curlyS' : curlyS,\n",
    "    'acc' : acc    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a24dbf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# 10. Backward stepwise selection\n",
    "\n",
    "Complete the code for backward stepwise selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1e8a22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T01:01:18.458461Z",
     "iopub.status.busy": "2023-03-21T01:01:18.458249Z",
     "iopub.status.idle": "2023-03-21T01:01:45.226045Z",
     "shell.execute_reply": "2023-03-21T01:01:45.225528Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "curlyS = [set() for i in range(P+1)]\n",
    "curlyS[P] = set(features)\n",
    "acc = np.full(P+1,-np.inf)\n",
    "\n",
    "for p in range(...,...,...):\n",
    "    print(p)\n",
    "    \n",
    "    curlyA = [set() for i in range(...)]\n",
    "    acckappa = np.empty(...) \n",
    "    \n",
    "    candidate_features = np.sort(list(...)) \n",
    "    for kappa, phip in enumerate(candidate_features):\n",
    "        \n",
    "        # Akappa\n",
    "        curlyA[kappa] = ...\n",
    "        \n",
    "        # train the logistic regression model\n",
    "        xtrain = Xtrain[list(curlyA[kappa])]    \n",
    "        model = Pipeline([('scaler', StandardScaler()), \n",
    "                          ('logreg', LogisticRegression(random_state=rng_seed)) ])\n",
    "        model.fit(xtrain,ytrain) \n",
    "        \n",
    "        # evaluate the model\n",
    "        acckappa[kappa] = cross_val_score(model, xtrain, ytrain, cv=3, scoring='accuracy').mean()\n",
    "\n",
    "    kappastar = np.argmax(acckappa)\n",
    "    curlyS[p] = curlyA[kappastar]\n",
    "    acc[p] = acckappa[kappastar]\n",
    "\n",
    "# best p\n",
    "pstar = np.argmax(acc)\n",
    "\n",
    "# store the result\n",
    "bwd = {\n",
    "    'pstar' : pstar,\n",
    "    'curlyS' : curlyS,\n",
    "    'acc' : acc    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18a2a7a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# 11. Selected model\n",
    "\n",
    "Follow the prompts in the code cell below. Your answers should be coded and not hard-coded (i.e. the answer entered by hand)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aa2ef8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T01:01:45.228340Z",
     "iopub.status.busy": "2023-03-21T01:01:45.228147Z",
     "iopub.status.idle": "2023-03-21T01:01:45.479761Z",
     "shell.execute_reply": "2023-03-21T01:01:45.479294Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Set `fwd_pstar` to the optimal number of features chosen by forward selection (from `fwd`).\n",
    "fwd_pstar = ...\n",
    "\n",
    "# 2. Set `fwd_features` to the corresponsing optimal set of features \n",
    "fwd_features = ...\n",
    "\n",
    "# 3. Set `bwd_pstar` to the optimal number of features chosen by backward selection (from `bwd`).\n",
    "bwd_pstar = ...\n",
    "\n",
    "# 4. Set `bwd_features` to the corresponsing optimal set of features \n",
    "bwd_features = ...\n",
    "\n",
    "# 5. Do the two agree on the optimal sets? (boolean answer)\n",
    "they_agree = ...\n",
    "\n",
    "# 6. The plot shows the validation accuracy for the forward algorithm as a function of the number of features. \n",
    "#    Overlay this plot with the corresponding line for the backward case. \n",
    "fig = plt.figure(figsize=(8,4))\n",
    "\n",
    "plt.plot(range(P+1),fwd['acc'],'o-',color='b',label='forward',linewidth=2)\n",
    "plt.plot(fwd['pstar'],fwd['acc'][fwd['pstar']],'*',color='b',markersize=14)\n",
    "\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.grid(linestyle=':')\n",
    "plt.xlabel('p',fontsize=16)\n",
    "plt.ylabel('validation accuracy',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61b7d3c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad73b0bc",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<h1><center><font color='purple'>Regularization</font><br></center></h1>\n",
    "\n",
    "\n",
    "# 12. LASSO regularized logistic regression\n",
    "\n",
    "General regularization is a method for avoiding overfitting by penalizing the complexity of the model in the training process. LASSO regularization in particular penalizes the sum of the absolute values of the parameters. It has the property that it will tend to \"zero out\" coefficients as the weight assigned to the penalty ($\\lambda$ from the notes) increases. This gives it an additional use as a feature selector. \n",
    "\n",
    "In this part we will train a LASSO logistic regression model. Instead of $\\lambda$, we will use the `C` parameter of `LogisticRegression`, which is the inverse of $\\lambda$. \n",
    "\n",
    "The code iterates through a logarithmically spaced array of regularization parameters `C`. For each value it trains and evaluates a logistic regression pipeline with the regularization parameter set to that value. Complete the code. When building the pipeline, you should pass these parameters to the LogisticRegression constructor. \n",
    "\n",
    "```python \n",
    "C=C[c],\n",
    "penalty='l1',\n",
    "solver='liblinear',\n",
    "```\n",
    "\n",
    "(in addition to setting the random state). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add20d94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T01:01:45.508221Z",
     "iopub.status.busy": "2023-03-21T01:01:45.508046Z",
     "iopub.status.idle": "2023-03-21T01:01:46.351592Z",
     "shell.execute_reply": "2023-03-21T01:01:46.350922Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "C = np.logspace(-2,2,20)\n",
    "acc = np.empty(20)\n",
    "models = list()\n",
    "\n",
    "for c in range(len(C)):   \n",
    "    \n",
    "    print(c)\n",
    "    \n",
    "    model = ...\n",
    "    model.fit(...,...)\n",
    "    \n",
    "    models.append(model)\n",
    "\n",
    "    # Validation accuracy\n",
    "    acc[c] = cross_val_score(model, Xtrain, ytrain, cv=3, scoring='accuracy').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4006b54d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8fc829",
   "metadata": {},
   "source": [
    "# 13. Selected model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1835dd",
   "metadata": {},
   "source": [
    "The next step is to select the model with the best validation accuracy. Follow the steps in the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2deaa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T01:01:46.362738Z",
     "iopub.status.busy": "2023-03-21T01:01:46.362079Z",
     "iopub.status.idle": "2023-03-21T01:01:47.259825Z",
     "shell.execute_reply": "2023-03-21T01:01:47.259236Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Set `cstar` to the index of the best performing regularization value\n",
    "cstar = ...\n",
    "\n",
    "# 2. Set `acc_star` to the corresponding accuracy value\n",
    "acc_star = ...\n",
    "\n",
    "# The next bit of code extracts the coefficients of the logistic regression for each of the 20 values of `C`. \n",
    "# This is stored in `theta` , which is a (20,30) array. (30 is the number of features)\n",
    "theta = np.vstack([model.named_steps['logreg'].coef_[0,:] for model in models])\n",
    "\n",
    "# 3. Plot the validation accuracy as a function of `C`, just as we plotted it as a function of `p` in part 11.\n",
    "fig1 = plt.figure(figsize=(8,4))\n",
    "...\n",
    "\n",
    "# 4. In a single plot, plot the 30 coefficients as a fucntion of `C`.\n",
    "fig2 = plt.figure(figsize=(8,4))\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339b4312",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q13\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9222a3a",
   "metadata": {},
   "source": [
    "# 14. Best features\n",
    "\n",
    "The plot below shows the coefficients for the best-case regularized logistic regression found in the previous part. Notice that many of these coefficients have been set to zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f83aced",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T01:01:47.273165Z",
     "iopub.status.busy": "2023-03-21T01:01:47.272997Z",
     "iopub.status.idle": "2023-03-21T01:01:47.404061Z",
     "shell.execute_reply": "2023-03-21T01:01:47.403473Z"
    }
   },
   "outputs": [],
   "source": [
    "theta_star = theta[cstar,:]\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.stem(np.abs(theta_star))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14141704",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T01:01:47.406328Z",
     "iopub.status.busy": "2023-03-21T01:01:47.406131Z",
     "iopub.status.idle": "2023-03-21T01:01:47.410681Z",
     "shell.execute_reply": "2023-03-21T01:01:47.410231Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Set `best_features` to the set of feature names corresponding to non-zero coefficients in the plot above. \n",
    "best_features = ...\n",
    "\n",
    "# 2. Set `max_theta_feature` to the feature name corresponding to the coefficient with maximum absolute value. \n",
    "max_theta_feature = ...\n",
    "\n",
    "# 3. Save the selected lasso model to the variable `lasso`.\n",
    "lasso = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee4cc2d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ff646c",
   "metadata": {},
   "source": [
    "# 15. Testing\n",
    "\n",
    "Use the test dataset to evaluate the accuracy of the selected LASSO model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0268882",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T01:01:47.432679Z",
     "iopub.status.busy": "2023-03-21T01:01:47.432495Z",
     "iopub.status.idle": "2023-03-21T01:01:47.438896Z",
     "shell.execute_reply": "2023-03-21T01:01:47.438377Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "yhat = ...\n",
    "lasso_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013dbfd5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96484d64",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dd1116",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q11": {
     "name": "q11",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> fwd_pstar==26\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> fwd_features=={'area error',\n...  'compactness error',\n...  'concave points error',\n...  'concavity error',\n...  'fractal dimension error',\n...  'mean area',\n...  'mean compactness',\n...  'mean concave points',\n...  'mean concavity',\n...  'mean fractal dimension',\n...  'mean perimeter',\n...  'mean radius',\n...  'mean smoothness',\n...  'mean texture',\n...  'perimeter error',\n...  'radius error',\n...  'smoothness error',\n...  'texture error',\n...  'worst area',\n...  'worst compactness',\n...  'worst concave points',\n...  'worst concavity',\n...  'worst fractal dimension',\n...  'worst smoothness',\n...  'worst symmetry',\n...  'worst texture'}\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> bwd_pstar==18\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> bwd_features=={'area error',\n...  'compactness error',\n...  'concave points error',\n...  'fractal dimension error',\n...  'mean concavity',\n...  'mean fractal dimension',\n...  'mean symmetry',\n...  'radius error',\n...  'smoothness error',\n...  'worst area',\n...  'worst concave points',\n...  'worst concavity',\n...  'worst fractal dimension',\n...  'worst perimeter',\n...  'worst radius',\n...  'worst smoothness',\n...  'worst symmetry',\n...  'worst texture'}\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> they_agree==False\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q12": {
     "name": "q12",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.all(np.isclose(acc,[0.89679912, 0.92315848, 0.92755896, 0.94514639, 0.95827524,\n...        0.96925468, 0.96706169, 0.96266121, 0.96709074, 0.96488323,\n...        0.96488323, 0.96269025, 0.96267573, 0.96267573, 0.95827524,\n...        0.95609678, 0.95171082, 0.94950331, 0.94948879, 0.94729581],1e-3))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q13": {
     "name": "q13",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> cstar==5\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(acc_star,0.9692546764261647,1e-3)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q14": {
     "name": "q14",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> \n>>> set(best_features)=={'mean concave points',\n...  'radius error',\n...  'worst concave points',\n...  'worst radius',\n...  'worst smoothness',\n...  'worst symmetry',\n...  'worst texture'}\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> \n>>> max_theta_feature=='worst radius'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.all(np.isclose(lasso.named_steps['logreg'].coef_[0,:],[0.        , 0.        , 0.        , 0.        , 0.        ,\n...        0.        , 0.        , 0.73708439, 0.        , 0.        ,\n...        0.49742808, 0.        , 0.        , 0.        , 0.        ,\n...        0.        , 0.        , 0.        , 0.        , 0.        ,\n...        2.00925427, 0.7288694 , 0.        , 0.        , 0.21378322,\n...        0.        , 0.        , 0.87670019, 0.08482143, 0.        ],1e-3))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q15": {
     "name": "q15",
     "points": null,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> Xtrain.shape==(455, 30)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> Xtest.shape==(114, 30)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> Xtrain_norm.shape==(455, 30)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> np.all(np.isclose(Xtrain_norm.mean(),0,1e-4))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> Xtest_norm.shape==(114, 30)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.all(np.isclose(Xtest_norm.mean(),0,1e-4))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.all(np.isclose(model_norm.intercept_[0],-1.0850505229077547,1e-3))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.all(np.isclose(model_norm.coef_[0,:],[3.44438434],1e-3))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(acc_nonorm,0.7186882769838503,1e-3)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(acc_norm,0.9077785523411176,1e-3)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.all(np.isclose(pipe.named_steps['scaler'].scale_,[0.06523992],1e-3))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(pipe.named_steps['logreg'].intercept_[0], -1.0850505229077547, 1e-3)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.all(np.isclose(pipe.named_steps['logreg'].coef_[0,:], [3.44438434], 1e-3))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8": {
     "name": "q8",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(acc_nonorm_test,0.7894736842105263,1e-3)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(acc_norm_test,0.9298245614035088,1e-3)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(acc_pipe_test,0.9210526315789473,1e-3)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
